{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packaes to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing=pd.read_csv('../input/california-housing-prices/housing.csv')\nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the type of \"ocean_proximity\" is object but since it's loaded from a csv file it must be a text attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing['ocean_proximity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.hist(bins=50,figsize=(20,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_train_test(data,test_ratio):\n    np.random.seed(42)\n    shuffled_indices=np.random.permutation(len(data))\n    test_set_size=int(len(data)*test_ratio)\n    test_indices=shuffled_indices[:test_set_size]\n    train_indices=shuffled_indices[test_set_size:]\n    return data.iloc[train_indices],data.iloc[test_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set,test_set=split_train_test(housing,0.2)\ntrain_set.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_set),'train +',len(test_set),'test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(housing.corr(),vmin=-1,vmax=1,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"as we see there is an important relation between median_house_value and median_income"},{"metadata":{},"cell_type":"markdown","source":"so , let's create an income category attribute by dividing the median income by 1.5"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing['median_income'].hist(bins=30,figsize=(20,15))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"most median values are clustred around 2-5 but some income go far beyond 6."},{"metadata":{"trusted":true},"cell_type":"code","source":"housing['income_cat']=np.ceil(housing['median_income']/1.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.income_cat\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's merge all the categories grater than 5 into category 5\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing['income_cat'].where(housing['income_cat']<5,5.0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.income_cat\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.columns\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Visualize our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scatter plot\nhousing.plot(kind='scatter',x='longitude',y='latitude',alpha=0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"===> it looks like California , we can see the high-density areas , Bay area around Los Angelos and San Diego"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.plot(kind='scatter',x='longitude',y='latitude',s=housing['population']/100,c=\"median_house_value\",label='population',cmap=plt.get_cmap(\"jet\"),colorbar=True,alpha=0.1)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the housing prices are very much related tp the location and to the population density "},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix=housing.corr()\nprint(corr_matrix)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how much attributes correlates with the median house value"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix['median_house_value'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see the most promosing attribute to predict the median house value is the median income ( 0.688), so let's zoom in on their correlation scatterplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.plot(kind='scatter',x='median_income',y='median_house_value',alpha=0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"this correlation is very strong, the points are not too dispersed "},{"metadata":{},"cell_type":"markdown","source":"Now, after discovering our data , we want to clean it !"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the total rooms doesn't give us any additional information , but i think that the number of rooms per household will help us !"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing['rooms_per_household']=housing['total_rooms']/housing['households']\nhousing['bedrooms_per_room']=housing['total_bedrooms']/housing['total_bedrooms']\nhousing['population_per_household']=housing['population']/housing['households']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the correlation matrix again"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix=housing.corr()\ncorr_matrix['median_house_value'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not bad ! , as we see the new rooms_per_household  is much more correlated with the median house value"},{"metadata":{},"cell_type":"markdown","source":"Data Cleaning:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=housing.drop('median_house_value',axis=1)\nY=housing['median_house_value']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy='median')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#median can only computedon numerical attribues \n#We need to drop ocean_proximity column \nhousing_num=x_train.drop('ocean_proximity',axis=1)\nimputer.fit(housing_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer.statistics_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_num.median().values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now , we will use the trained imputer to transform the training set by replacing the missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_imputed=imputer.transform(housing_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_imputed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This will return a numpy array, Let's back into a Pandas DataFrame"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_trainig=pd.DataFrame(housing_imputed,columns=housing_num.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n#We instanciate our encoder\nencoder=LabelEncoder()\n#We extract our column that is going to be encoded \nhousing_cat=x_train['ocean_proximity']\nhousing_cat_encoded=encoder.fit_transform(housing_cat)\nhousing_cat_encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(encoder.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nencoder=OneHotEncoder()\nhousing_cat_1hot=encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\nhousing_cat_1hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_cat_1hot.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\nencoder=LabelBinarizer()\nhousing_cat_1hot=encoder.fit_transform(housing_cat)\nhousing_cat_1hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator,TransformerMixin\nrooms_ix,bedrooms_ix, population_ix,household_ix=3,4,5,6\nclass CombinedAttributesAdder(BaseEstimator,TransformerMixin):\n    def __init__(self,add_bedrooms_per_room=True):\n        self.add_bedrooms_per_room=add_bedrooms_per_room\n    def fit(self,X,y=None):\n        return self\n    def transform(self,X,y=None):\n        rooms_per_household=X[:,rooms_ix]/X[:,household_ix]\n        population_per_household=X[:,population_ix]/X[:,household_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room=X[:,bedrooms_ix]/X[:,rooms_ix]\n            return np.c_[X,rooms_per_household,population_per_household,bedrooms_per_room]\n        else :\n            return np.c_[X,rooms_per_household,population_per_household]\n        \nattr_adder=CombinedAttributesAdder(add_bedrooms_per_room=False)\nhousing_extra_attributes=attr_adder.transform(housing.values)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Featue Scaling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_num.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see the numerical attributes has different scales, this will cause a problem when we use Machine Learning Algorithms."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_pipeline=Pipeline([('imputer',SimpleImputer(strategy='median')),\n                  \n                        ('attribs_addr',CombinedAttributesAdder()),\n                        ('std_scaler',StandardScaler())\n                       ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_num_tr=num_pipeline.fit_transform(housing_num)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now , let's come back to categorical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import FeatureUnion","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataFrameSelector(BaseEstimator,TransformerMixin):\n    def __init__(self,attribute_names):\n        self.attribute_names=attribute_names\n    def fit(self,X,y=None):\n        return self\n    def transform(self,X):\n        return X[self.attribute_names].values\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SupervisionFriendlyLabelBinarizer(LabelBinarizer):\n    def fit_transform(self, X, y=None):\n        return super(SupervisionFriendlyLabelBinarizer,self).fit_transform(X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_attribs=list(housing_num)\ncat_attribs=['ocean_proximity']\nnum_pipeline=Pipeline([\n    ('selector',DataFrameSelector(num_attribs)),\n    ('imputer',SimpleImputer()),\n    ('attribs_adder',CombinedAttributesAdder()),\n    ('std_scaler',StandardScaler()),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_pipeline=Pipeline([\n    ('selector',DataFrameSelector(cat_attribs)),\n    ('label_binarizer',SupervisionFriendlyLabelBinarizer()),\n    \n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_pipeline=FeatureUnion(transformer_list=[\n    ('num_pipeline',num_pipeline),\n    ('cat_pipeline',cat_pipeline)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's run the whole pipeline\n\nhousing_prepared=full_pipeline.fit_transform(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_prepared","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n#Instanciate our model\nlin_reg=LinearRegression()\nlin_reg.fit(housing_prepared,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"some_data=x_train.iloc[:5]\nsome_labels=y_train.iloc[:5]\nsome_data_prepared=full_pipeline.transform(some_data)\nprint('Predictions :\\t',lin_reg.predict(some_data_prepared))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Labes :\\t',list(some_labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's evaluate:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nhousing_predictions=lin_reg.predict(housing_prepared)\nlin_mse=mean_squared_error(y_train,housing_predictions)\nprint(np.sqrt(lin_mse))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's select more powerful model \"DecisionTreeRegressor\""},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ntree_reg=DecisionTreeRegressor()\ntree_reg.fit(housing_prepared,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's Predict\nhousing_predictions=tree_reg.predict(housing_prepared)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's evaluate\ntree_mse=mean_squared_error(y_train,housing_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.sqrt(tree_mse))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"==> this is not good at all , this means that we are suffering from the 'overfitting' problem , to solve this we are going to use scikit learn cross-validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"display the scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_scores(scores):\n    print(\"Scores\",scores)\n    print(\"Mean\",scores.mean())\n    print(\"Standard Deviation :\",scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse_tree_scores=cross_val_score(tree_reg,housing_prepared,y_train,scoring='neg_mean_squared_error',cv=10)\nrmse_tree_scores=np.sqrt(-mse_tree_scores)\ndisplay_scores(rmse_tree_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse_lin_scores=cross_val_score(lin_reg,housing_prepared,y_train,scoring='neg_mean_squared_error',cv=10)\nrmse_lin_scores=np.sqrt((-mse_lin_scores))\ndisplay_scores(rmse_lin_scores)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"The two models are so bad , let's try another RandomForestRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nforest_reg=RandomForestRegressor()\nforest_reg.fit(housing_prepared,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's predict\nhousing_predictions=forest_reg.predict(housing_prepared)\nmse_forest=mean_squared_error(y_train,housing_predictions)\nprint(np.sqrt(mse_forest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse_forest_scores=cross_val_score(forest_reg,housing_prepared,y_train,scoring='neg_mean_squared_error',cv=10)\nrmse_forest_scores=np.sqrt((-mse_forest_scores))\ndisplay_scores(rmse_forest_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fine tune our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid=[{'n_estimators':[3,10,30],'max_features':[2,4,6,8]},\n            {'bootstrap':[False],'n_estimators':[3,10],'max_features':[2,3,4]},]\nforest_reg=RandomForestRegressor()\ngrid_search=GridSearchCV(forest_reg,param_grid,cv=5,scoring='neg_mean_squared_error')\ngrid_search.fit(housing_prepared,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores=grid_search.cv_results_\nfor mean_score,params in zip(scores['mean_test_score'],scores['params']):\n    print(np.sqrt(-mean_score),params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"===> as we see the best score when we set our parameters to 6 as max_features and 30 n_estimators"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model=grid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_prepared=full_pipeline.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now, let's predict \nfinal_predictions=final_model.predict(x_test_prepared)\n#Let's evaluate our model\nfinal_mse=mean_squared_error(y_test,final_predictions)\nprint(np.sqrt(final_mse))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's load our modal"},{"metadata":{"trusted":true},"cell_type":"code","source":"import joblib\nfilname='finalized_model.csv'\njoblib.dump(final_model, filename)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}